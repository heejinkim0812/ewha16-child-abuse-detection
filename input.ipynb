{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "input.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p3bble123/ewha16-child-abuse-detection/blob/main/input.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWoxao-SfkhR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d8b988e-4bbe-471a-c494-50f4a1af330a"
      },
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 tensorflow-hub opencv-python matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 13 kB/s \n",
            "\u001b[?25hCollecting tensorflow-gpu==2.4.1\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out. (read timeout=15)\")': /packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl\u001b[0m\n",
            "  Downloading tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 14 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.17.3)\n",
            "Collecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 82.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.6.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.37.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 73.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (57.4.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, h5py, gast, tensorflow-gpu, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.40.0\n",
            "    Uninstalling grpcio-1.40.0:\n",
            "      Successfully uninstalled grpcio-1.40.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "Successfully installed gast-0.3.3 grpcio-1.32.0 h5py-2.10.0 tensorflow-2.4.1 tensorflow-estimator-2.4.0 tensorflow-gpu-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kCQ97qPr1eR"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ToiNfljr2vl"
      },
      "source": [
        "# Optional if you are using a GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCaT9PwMr5VV"
      },
      "source": [
        "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
        "movenet = model.signatures['serving_default']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkgxCh5Pr6_E"
      },
      "source": [
        "# 어른 아이 구분 함수\n",
        "\n",
        "def separate_adult(frame, current_keypoints, confidence_threshold):\n",
        "\n",
        "  # keypoints를 frame 크기에 normalize\n",
        "  y,x,c = frame.shape\n",
        "  shaped = np.squeeze(np.multiply(current_keypoints, [y,x,1]))\n",
        "  \n",
        "  i = 0\n",
        "  adult_index = 0\n",
        "  max_height = 0\n",
        "\n",
        "  for person in shaped:\n",
        "\n",
        "    # confidence가 역치 이상일 때 키 추출\n",
        "    if (person[5][2] > confidence_threshold) and (person[6][2] > confidence_threshold) and (person[11][2] > confidence_threshold) and (person[12][2] > confidence_threshold):\n",
        "       \n",
        "       m = (person[5][0]+person[6][0])/2, (person[5][1]+person[6][1])/2      # shoulder 중점\n",
        "       n = (person[11][0]+person[12][0])/2, (person[11][1]+person[12][1])/2  # hip 중점\n",
        "       \n",
        "       # height 구하기 (m과 n 사이의 거리)\n",
        "       height =  (((n[0]-m[0])**2) + ((n[1]-m[1])**2)) ** 0.5\n",
        "  \n",
        "       if height > max_height:\n",
        "         max_height = height\n",
        "         adult_index = i\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  return adult_index \n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-0Q7Kq5JBM1"
      },
      "source": [
        "def sub(x1,x2):\n",
        "  return x1[0] - x2[0],x1[1] - x2[1]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIxSIx7wh33V"
      },
      "source": [
        "# keypoint별 벡터 크기(속력) 구하기\n",
        "def keypoint_vector(frame, previous_keypoints, current_keypoints, confidence_threshold):\n",
        "  \n",
        "  # keypoints를 frame 크기에 normalize\n",
        "  y,x,c = frame.shape\n",
        "  c_shaped = np.squeeze(np.multiply(current_keypoints, [y,x,1]))\n",
        "  p_shaped = np.squeeze(np.multiply(previous_keypoints, [y,x,1]))\n",
        "  \n",
        "  # 이전 프레임과 현재 프레임의 Adult keypoints\n",
        "  p_adult_keypoints = p_shaped[separate_adult(frame, previous_keypoints, 0.3)]\n",
        "  c_adult_keypoints = c_shaped[separate_adult(frame, current_keypoints, 0.3)]\n",
        "\n",
        "  # 벡터 차이 구하기\n",
        "  vector = np.zeros((17,2)) \n",
        "  for i in range(17):\n",
        "    # confidence 역치 이상일 때만\n",
        "    if (c_adult_keypoints[i][2] >= confidence_threshold) and (p_adult_keypoints[i][2] >= confidence_threshold):\n",
        "      vector[i][0] = c_adult_keypoints[i][0] - p_adult_keypoints[i][0]\n",
        "      vector[i][1] = c_adult_keypoints[i][1] - p_adult_keypoints[i][1]\n",
        "    else:\n",
        "      vector[i] = [0,0]\n",
        "\n",
        "  return vector\n",
        "  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsV92u75HEqb"
      },
      "source": [
        "def relationKeypoint(frame,current_keypoints,confidence_threshold,distanceArray):\n",
        "  # keypoints를 frame 크기에 normalize\n",
        "  y,x,c = frame.shape\n",
        "  shaped = np.squeeze(np.multiply(current_keypoints, [y,x,1]))\n",
        "  \n",
        "  # 이전 프레임과 현재 프레임의 Adult keypoints\n",
        "  adult_keypoints = shaped[separate_adult(frame, current_keypoints, 0.3)]\n",
        "\n",
        "  # 벡터 차이 구하기\n",
        "  vector = np.zeros((22,1)) \n",
        "  #f4\n",
        "  d4 = distanceArray[0] + distanceArray[2] + distanceArray[3] + distanceArray[5] +distanceArray[6]\n",
        "  vector[0],vector[1] = sub(adult_keypoints[0],adult_keypoints[1])/d4\n",
        "  vector[2],vector[3] = sub(adult_keypoints[6],adult_keypoints[1])/d4\n",
        "  vector[4],vector[5] = sub(adult_keypoints[7],adult_keypoints[1])/d4\n",
        "  #f5\n",
        "  d5 = distanceArray[2] + distanceArray[3] + distanceArray[9] + distanceArray[11] \n",
        "  vector[6],vector[7] = sub(adult_keypoints[1],adult_keypoints[8])/d5\n",
        "  vector[8],vector[9] = sub(adult_keypoints[7],adult_keypoints[8])/d5\n",
        "  vector[10],vector[11] = sub(adult_keypoints[13],adult_keypoints[8])/d5\n",
        "  #f6\n",
        "  d6 = distanceArray[5] + distanceArray[6] + distanceArray[10] + distanceArray[12] \n",
        "  vector[12],vector[13] = sub(adult_keypoints[0],adult_keypoints[9])/d5\n",
        "  vector[14],vector[15] = sub(adult_keypoints[6],adult_keypoints[9])/d5\n",
        "  vector[16],vector[17] = sub(adult_keypoints[12],adult_keypoints[9])/d5\n",
        "  #f7\n",
        "  d7 = distanceArray[2] + distanceArray[3] + distanceArray[5] + distanceArray[6] \n",
        "  vector[18],vector[19] = sub(adult_keypoints[7],adult_keypoints[0])/d7\n",
        "  vector[20],vector[21] = sub(adult_keypoints[6],adult_keypoints[0])/d7\n",
        "\n",
        "  return vector\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV7vZnYgBU07"
      },
      "source": [
        "import math\n",
        "\n",
        "def dist(x1,x2) -> int:\n",
        "  x = x1[0]-x2[0]\n",
        "  y = x1[1]-x2[1]\n",
        "  return math.sqrt(x**2 + y**2)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL0BEHyfXefx"
      },
      "source": [
        "def distanceVector(norm_vector):\n",
        "  distanceArray = np.zeros((13,1))\n",
        "  \n",
        "  distanceArray[0] = dist((norm_vector[0],norm_vector[1]),(norm_vector[2],norm_vector[3]))\n",
        "  distanceArray[1] = dist((norm_vector[2],norm_vector[3]),(norm_vector[6],norm_vector[7]))\n",
        "  distanceArray[2] = dist((norm_vector[6],norm_vector[7]),(norm_vector[10],norm_vector[11]))\n",
        "  distanceArray[3] = dist((norm_vector[10],norm_vector[11]),(norm_vector[14],norm_vector[15]))\n",
        "  distanceArray[4] = dist((norm_vector[2],norm_vector[3]),(norm_vector[4],norm_vector[5]))\n",
        "  distanceArray[5] = dist((norm_vector[4],norm_vector[5]),(norm_vector[8],norm_vector[9]))\n",
        "  distanceArray[6] = dist((norm_vector[8],norm_vector[9]),(norm_vector[12],norm_vector[13]))\n",
        "  distanceArray[7] = dist((norm_vector[2],norm_vector[3]),(norm_vector[18],norm_vector[19]))\n",
        "  distanceArray[8] = dist((norm_vector[2],norm_vector[3]),(norm_vector[16],norm_vector[17]))\n",
        "  distanceArray[9] = dist((norm_vector[18],norm_vector[19]),(norm_vector[22],norm_vector[23]))\n",
        "  distanceArray[10] = dist((norm_vector[16],norm_vector[17]),(norm_vector[20],norm_vector[21]))\n",
        "  distanceArray[11] = dist((norm_vector[22],norm_vector[23]),(norm_vector[26],norm_vector[27]))\n",
        "  distanceArray[12] = dist((norm_vector[20],norm_vector[21]),(norm_vector[24],norm_vector[25]))\n",
        "\n",
        "  return distanceArray"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZfy7_4_zsXf"
      },
      "source": [
        "def normalize(frame, previous_keypoints, current_keypoints, confidence_threshold) :\n",
        "  norm_vector = np.zeros((28,1))\n",
        "  distanceArray = np.zeros((13,1))\n",
        "  relationVector = np.zeros((22,1))\n",
        "  final_vector = np.zeros((50,1))\n",
        "  vector = keypoint_vector(frame, previous_keypoints, current_keypoints, 0.3)\n",
        "  #head\n",
        "  norm_vector[0],norm_vector[1] = (vector[1][0]+vector[2][0])//2,(vector[1][1]+vector[2][1])//2\n",
        "  #neck\n",
        "  norm_vector[2],norm_vector[3] = (norm_vector[0]+vector[5][0]+ vector[6][0])//3,(norm_vector[1]+vector[5][1]+ vector[6][1])//3\n",
        "\n",
        "  #norm_vector로 옮기기 (14포인트)\n",
        "  for i,points in enumerate(vector):\n",
        "    x_idx,y_idx = (i-3)*2,((i-3)*2)+1\n",
        "    norm_vector[x_idx] = points[0]\n",
        "    norm_vector[y_idx] = points[1]\n",
        "  \n",
        "  # 신체 거리 구하기\n",
        "  \n",
        "  distanceArray = distanceVector(norm_vector)\n",
        "\n",
        "  #변위 벡터 계산\n",
        "  \n",
        "  #f1\n",
        "  d1 = distanceArray[0] + distanceArray[3] + distanceArray[6] + distanceArray[11] +distanceArray[12]\n",
        "  norm_vector[0],norm_vector[1] = norm_vector[0]/d1,norm_vector[1]/d1\n",
        "  norm_vector[12],norm_vector[13] = norm_vector[12]/d1,norm_vector[13]/d1\n",
        "  norm_vector[14],norm_vector[15] = norm_vector[14]/d1,norm_vector[15]/d1\n",
        "  norm_vector[24],norm_vector[25] = norm_vector[24]/d1,norm_vector[25]/d1\n",
        "  norm_vector[26],norm_vector[27] = norm_vector[26]/d1,norm_vector[27]/d1\n",
        "\n",
        "  #f2\n",
        "  d2 = distanceArray[0] + distanceArray[2] + distanceArray[5] + distanceArray[9] +distanceArray[10]\n",
        "  norm_vector[2],norm_vector[3] = norm_vector[2]/d1,norm_vector[3]/d1\n",
        "  norm_vector[8],norm_vector[9] = norm_vector[8]/d1,norm_vector[9]/d1\n",
        "  norm_vector[10],norm_vector[11] = norm_vector[10]/d1,norm_vector[11]/d1\n",
        "  norm_vector[20],norm_vector[21] = norm_vector[20]/d1,norm_vector[21]/d1\n",
        "  norm_vector[22],norm_vector[23] = norm_vector[22]/d1,norm_vector[23]/d1\n",
        "  #f3\n",
        "  d3 = distanceArray[1] + distanceArray[4] + distanceArray[9] + distanceArray[10] \n",
        "  norm_vector[4],norm_vector[5] = norm_vector[4]/d1,norm_vector[5]/d1\n",
        "  norm_vector[6],norm_vector[7] = norm_vector[6]/d1,norm_vector[7]/d1\n",
        "  norm_vector[16],norm_vector[17] = norm_vector[16]/d1,norm_vector[17]/d1\n",
        "  norm_vector[18],norm_vector[19] = norm_vector[18]/d1,norm_vector[19]/d1\n",
        "  \n",
        "  relationVector = relationKeypoint(frame,current_keypoints,confidence_threshold,distanceArray)\n",
        "\n",
        "  final_vector = np.concatenate((norm_vector, relationVector), axis=0)\n",
        "  return final_vector"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3vuXMVwjJ89",
        "outputId": "819b8d6f-dca2-4da2-d036-35404fde76b6"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive/')\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWv5Gvesu-ik",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9ec02c4e-ecd8-4dbc-cb48-9d1c2c1af204"
      },
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "cap = cv2.VideoCapture('/content/gdrive/MyDrive/novak.mp4')\n",
        "prevImg = None\n",
        "current_keypoints = None\n",
        "previous_keypoints = None\n",
        "input = np.zeros((50,1))\n",
        "\n",
        "while cap.isOpened():\n",
        "\n",
        "    ret, frame = cap.read()\n",
        "    # Resize image\n",
        "    img = frame.copy()\n",
        "    img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
        "    input_img = tf.cast(img, dtype=tf.int32)\n",
        "    \n",
        "    if prevImg is None:    \n",
        "      prevImg = input_img\n",
        "\n",
        "      # Detection section\n",
        "      results1 = movenet(prevImg)\n",
        "\n",
        "      # 17개의 키포인트: nose, Leye, Reye, Lear, Rear, Lshoulder, Rshoulder, Lelbow, Relbow, Lwrist, Rwrist, Lhip, Rhip, Lknee, Rknee, Lankle, Rankle\n",
        "      previous_keypoints = results1['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
        "\n",
        "    else:\n",
        "      currentImg = input_img\n",
        "\n",
        "      # Detection section\n",
        "      results2 = movenet(currentImg)\n",
        "\n",
        "      # 17개의 키포인트: nose, Leye, Reye, Lear, Rear, Lshoulder, Rshoulder, Lelbow, Relbow, Lwrist, Rwrist, Lhip, Rhip, Lknee, Rknee, Lankle, Rankle\n",
        "      current_keypoints = results2['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
        "\n",
        "      # 다음 프레임을 위한 프레임 이월\n",
        "      prevImg = currentImg\n",
        "\n",
        "      #프레임마다 input계산\n",
        "      vector = normalize(frame, previous_keypoints, current_keypoints, 0.3)\n",
        "\n",
        "      #프레임 별로 합치기\n",
        "      input = np.append(input, vector , axis = 1)\n",
        "      \n",
        "      #확인\n",
        "      print(input.shape)\n",
        "      \n",
        "\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
        "        break\n",
        "\n",
        "\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 2)\n",
            "(50, 3)\n",
            "(50, 4)\n",
            "(50, 5)\n",
            "(50, 6)\n",
            "(50, 7)\n",
            "(50, 8)\n",
            "(50, 9)\n",
            "(50, 10)\n",
            "(50, 11)\n",
            "(50, 12)\n",
            "(50, 13)\n",
            "(50, 14)\n",
            "(50, 15)\n",
            "(50, 16)\n",
            "(50, 17)\n",
            "(50, 18)\n",
            "(50, 19)\n",
            "(50, 20)\n",
            "(50, 21)\n",
            "(50, 22)\n",
            "(50, 23)\n",
            "(50, 24)\n",
            "(50, 25)\n",
            "(50, 26)\n",
            "(50, 27)\n",
            "(50, 28)\n",
            "(50, 29)\n",
            "(50, 30)\n",
            "(50, 31)\n",
            "(50, 32)\n",
            "(50, 33)\n",
            "(50, 34)\n",
            "(50, 35)\n",
            "(50, 36)\n",
            "(50, 37)\n",
            "(50, 38)\n",
            "(50, 39)\n",
            "(50, 40)\n",
            "(50, 41)\n",
            "(50, 42)\n",
            "(50, 43)\n",
            "(50, 44)\n",
            "(50, 45)\n",
            "(50, 46)\n",
            "(50, 47)\n",
            "(50, 48)\n",
            "(50, 49)\n",
            "(50, 50)\n",
            "(50, 51)\n",
            "(50, 52)\n",
            "(50, 53)\n",
            "(50, 54)\n",
            "(50, 55)\n",
            "(50, 56)\n",
            "(50, 57)\n",
            "(50, 58)\n",
            "(50, 59)\n",
            "(50, 60)\n",
            "(50, 61)\n",
            "(50, 62)\n",
            "(50, 63)\n",
            "(50, 64)\n",
            "(50, 65)\n",
            "(50, 66)\n",
            "(50, 67)\n",
            "(50, 68)\n",
            "(50, 69)\n",
            "(50, 70)\n",
            "(50, 71)\n",
            "(50, 72)\n",
            "(50, 73)\n",
            "(50, 74)\n",
            "(50, 75)\n",
            "(50, 76)\n",
            "(50, 77)\n",
            "(50, 78)\n",
            "(50, 79)\n",
            "(50, 80)\n",
            "(50, 81)\n",
            "(50, 82)\n",
            "(50, 83)\n",
            "(50, 84)\n",
            "(50, 85)\n",
            "(50, 86)\n",
            "(50, 87)\n",
            "(50, 88)\n",
            "(50, 89)\n",
            "(50, 90)\n",
            "(50, 91)\n",
            "(50, 92)\n",
            "(50, 93)\n",
            "(50, 94)\n",
            "(50, 95)\n",
            "(50, 96)\n",
            "(50, 97)\n",
            "(50, 98)\n",
            "(50, 99)\n",
            "(50, 100)\n",
            "(50, 101)\n",
            "(50, 102)\n",
            "(50, 103)\n",
            "(50, 104)\n",
            "(50, 105)\n",
            "(50, 106)\n",
            "(50, 107)\n",
            "(50, 108)\n",
            "(50, 109)\n",
            "(50, 110)\n",
            "(50, 111)\n",
            "(50, 112)\n",
            "(50, 113)\n",
            "(50, 114)\n",
            "(50, 115)\n",
            "(50, 116)\n",
            "(50, 117)\n",
            "(50, 118)\n",
            "(50, 119)\n",
            "(50, 120)\n",
            "(50, 121)\n",
            "(50, 122)\n",
            "(50, 123)\n",
            "(50, 124)\n",
            "(50, 125)\n",
            "(50, 126)\n",
            "(50, 127)\n",
            "(50, 128)\n",
            "(50, 129)\n",
            "(50, 130)\n",
            "(50, 131)\n",
            "(50, 132)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-49aeb9b79d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_with_pad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0minput_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmgU7yjBkv25"
      },
      "source": [
        "# 새 섹션"
      ]
    }
  ]
}